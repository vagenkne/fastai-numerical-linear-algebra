{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 2 - Topic modeling using SVD and NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic modeling using SVD decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn import decomposition\n",
    "from scipy import linalg\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# very small numbers diplayed in scientific format\n",
    "np.set_printoptions(suppress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data will be donwload\n",
    "# first we have to specify which categories to download and what to remove from documents\n",
    "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "remove = ('headers','footers','quotes')\n",
    "# fetch_20newsgroups is dataset from scikitlearn\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories = categories, remove = remove)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories = categories, remove = remove)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2034,), (2034,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.filenames.shape, newsgroups_train.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi,\n",
      "\n",
      "I've noticed that if you only save a model (with all your mapping planes\n",
      "positioned carefully) to a .3DS file that when you reload it after restarting\n",
      "3DS, they are given a default position and orientation.  But if you save\n",
      "to a .PRJ file their positions/orientation are preserved.  Does anyone\n",
      "know why this information is not stored in the .3DS file?  Nothing is\n",
      "explicitly said in the manual about saving texture rules in the .PRJ file. \n",
      "I'd like to be able to read the texture rule information, does anyone have \n",
      "the format for the .PRJ file?\n",
      "\n",
      "Is the .CEL file format available from somewhere?\n",
      "\n",
      "Rych\n",
      "\n",
      "\n",
      "Seems to be, barring evidence to the contrary, that Koresh was simply\n",
      "another deranged fanatic who thought it neccessary to take a whole bunch of\n",
      "folks with him, children and all, to satisfy his delusional mania. Jim\n",
      "Jones, circa 1993.\n",
      "\n",
      "\n",
      "Nope - fruitcakes like Koresh have been demonstrating such evil corruption\n",
      "for centuries.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(newsgroups_train.data[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 2, 0, 2, 0, 2, 1, 2, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.target[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics, num_top_words = 6,8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorizer.fit_transform will learn (recognize) and save all the words form all the documents (posts)\n",
    "# and make matrix form it  [post-rows, words-columns]\n",
    "# matrix is called vectors\n",
    "vectorizer = CountVectorizer(stop_words = 'english')\n",
    "vectors = vectorizer.fit_transform(newsgroups_train.data).todense()\n",
    "vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2034 (2034, 26576)\n"
     ]
    }
   ],
   "source": [
    "# from a \"list\" of 2034 posts we have got 21240 words by using CountVectorizer function\n",
    "print(len(newsgroups_train.data), vectors.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_feature_names() is the vocabulary learnd ordered alphabetically\n",
    "vocab = np.array(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26576,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['factors', 'factory', 'facts', 'factsnet', 'factual'], dtype='<U80')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[10000:10005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decomposing a post/words matrix using SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.3 s, sys: 1.33 s, total: 31.6 s\n",
      "Wall time: 18.1 s\n"
     ]
    }
   ],
   "source": [
    "%time U, s, Vh = linalg.svd(vectors, full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2034, 2034) (2034,) (2034, 26576)\n"
     ]
    }
   ],
   "source": [
    "# dim\n",
    "print(U.shape, s.shape, Vh.shape)\n",
    "# original matrix is invertible - s is full rank matrix in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiply matricies to confirm that the the decomposition reconstructs the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9488546705018146e-12"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstructed_vectors = U @ np.diag(s) @ Vh\n",
    "np.linalg.norm(reconstructed_vectors - vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm that Vh and U are orthonormal\n",
    "np.allclose(Vh @ Vh.T, np.eye(Vh.shape[0]))\n",
    "np.allclose(U @ U.T, np.eye(U.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c07e470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot of singular values\n",
    "plt.plot(s);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c08f860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(s[:10]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.33926985e+02, 2.91510127e+02, 2.40711377e+02, ...,\n",
       "       1.68683622e-15, 1.41196638e-15, 1.27172738e-15])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_words = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_topics(a):\n",
    "    top_words = lambda t: [vocab[i] for i in np.argsort(t)[:-num_top_words-1:1]]\n",
    "    topic_words = ([top_words(t) for t in a])\n",
    "    return ['  '.join(t) for t in topic_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_top_words=10\n",
    "\n",
    "def show_topics(a):\n",
    "    top_words = lambda t: [vocab[i] for i in np.argsort(t)[:-num_top_words-1:-1]]\n",
    "    topic_words = ([top_words(t) for t in a])\n",
    "    return ['  '.join(t) for t in topic_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ditto  critus  propagandist  surname  galacticentric  kindergarten  surreal  imaginative  salvadorans  autotheism',\n",
       " 'jpeg  gif  file  color  quality  image  jfif  format  bit  version',\n",
       " 'graphics  edu  pub  mail  128  3d  ray  ftp  send  image',\n",
       " 'jesus  god  matthew  people  atheists  atheism  does  graphics  religious  said',\n",
       " 'image  data  processing  analysis  software  available  tools  display  tool  user']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_topics(Vh[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## below I tried to find the maximum value of the 0th row of Vh matrix it coresponds to a word ditto, the same result as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-9.40971949e-03, -1.14531979e-02, -2.16949925e-05, ...,\n",
       "       -5.71798766e-06, -1.14359753e-05, -1.09243411e-03])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vh[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '000', '0000', ..., 'zware', 'zwarte', 'zyxel'], dtype='<U80')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([8462]),)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(Vh[0,:] == np.max(Vh[0,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ditto'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[8462]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NMF - non negative matrix factorization\n",
    "# different matrix factorization \n",
    "# only approximate factorization\n",
    "# there are various different implementations of NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than constraining our factors to be *orthogonal*, another idea would to constrain them to be *non-negative*. NMF is a factorization of a non-negative data set $V$: $$ V = W H$$ into non-negative matrices $W,\\; H$. Often positive factors will be **more easily interpretable** (and this is the reason behind NMF's popularity). \n",
    "\n",
    "<img src=\"images/face_nmf.png\" alt=\"NMF on faces\" style=\"width: 80%\"/>\n",
    "\n",
    "(source: [NMF Tutorial](http://perso.telecom-paristech.fr/~essid/teach/NMF_tutorial_ICME-2014.pdf))\n",
    "\n",
    "Nonnegative matrix factorization (NMF) is a non-exact factorization that factors into one skinny positive matrix and one short positive matrix.  NMF is NP-hard and non-unique.  There are a number of variations on it, created by adding different constraints. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sources for more information on NMF\n",
    "- [Face Decompositions](http://scikit-learn.org/stable/auto_examples/decomposition/plot_faces_decomposition.html#sphx-glr-auto-examples-decomposition-plot-faces-decomposition-py)\n",
    "- [Collaborative Filtering, eg movie recommendations](http://www.quuxlabs.com/blog/2010/09/matrix-factorization-a-simple-tutorial-and-implementation-in-python/)\n",
    "- [Audio source separation](https://pdfs.semanticscholar.org/cc88/0b24791349df39c5d9b8c352911a0417df34.pdf)\n",
    "- [Chemistry](http://ieeexplore.ieee.org/document/1532909/)\n",
    "- [Bioinformatics](https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-015-0485-4) and [Gene Expression](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2623306/)\n",
    "- Topic Modeling (our problem!)\n",
    "<img src=\"images/nmf_doc.png\" alt=\"NMF on documents\" style=\"width: 80%\"/>\n",
    "\n",
    "(source: [NMF Tutorial](http://perso.telecom-paristech.fr/~essid/teach/NMF_tutorial_ICME-2014.pdf))\n",
    "- [The Why and How of Nonnegative Matrix Factorization](https://arxiv.org/pdf/1401.5226.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- NMF form sklearn\n",
    "[scikit-learn's implementation of NMF](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scikit learn implementation of NMF\n",
    "m,n = vectors.shape\n",
    "d = 5 #number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = decomposition.NMF(n_components=d, random_state =1)\n",
    "\n",
    "W1 = clf.fit_transform(vectors)\n",
    "H1 = clf.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jpeg  image  gif  file  color  images  format  quality  version  files',\n",
       " 'edu  graphics  pub  mail  128  ray  ftp  send  3d  com',\n",
       " 'space  launch  satellite  nasa  commercial  satellites  year  market  data  earth',\n",
       " 'jesus  god  people  matthew  atheists  does  atheism  said  just  believe',\n",
       " 'image  data  available  software  processing  ftp  edu  analysis  images  display']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_topics(H1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NMF implementatino from cratch using numpy and SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The key idea of standard **gradient descent**:\n",
    "1. Randomly choose some weights to start\n",
    "2. Loop:\n",
    "    - Use weights to calculate a prediction\n",
    "    - Calculate the derivative of the loss\n",
    "    - Update the weights\n",
    "3. Repeat step 2 lots of times.  Eventually we end up with some decent weights.\n",
    "\n",
    "**Key**: We want to decrease our loss and the derivative tells us the direction of **steepest descent**.  \n",
    "\n",
    "Note that *loss*, *error*, and *cost* are all terms used to describe the same thing.\n",
    "\n",
    "Let's take a look at the [Gradient Descent Intro notebook](gradient-descent-intro.ipynb) (originally from the [fast.ai deep learning course](https://github.com/fastai/courses))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stochastic gradient descent** is an incredibly useful optimization method (it is also the heart of deep learning, where it is used for backpropagation).\n",
    "\n",
    "For *standard* gradient descent, we evaluate the loss using **all** of our data which can be really slow.  In *stochastic* gradient descent, we evaluate our loss function on just a sample of our data (sometimes called a *mini-batch*).  We would get different loss values on different samples of the data, so this is *why it is stochastic*.  It turns out that this is still an effective way to optimize, and it's much more efficient!\n",
    "\n",
    "We can see how this works in this [excel spreadsheet](graddesc.xlsm) (originally from the [fast.ai deep learning course](https://github.com/fastai/courses))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal**: Decompose $V\\;(m \\times n)$ into $$V \\approx WH$$ where $W\\;(m \\times d)$ and $H\\;(d \\times n)$, $W,\\;H\\;>=\\;0$, and we've minimized the Frobenius norm of $V-WH$.\n",
    "\n",
    "**Approach**: We will pick random positive $W$ & $H$, and then use SGD to optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we have to do topic frequency - inverse document frequency (TF-IDF) \n",
    "# form of standardization of the word frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Topic Frequency-Inverse Document Frequency](http://www.tfidf.com/) (TF-IDF) is a way to normalize term counts by taking into account how often they appear in a document, how long the document is, and how commmon/rare the term is.\n",
    "\n",
    "TF = (# occurrences of term t in document) / (# of words in documents)\n",
    "\n",
    "IDF = log(# of documents / # documents with term t in it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_tfidf = TfidfVectorizer(stop_words='english')\n",
    "vectors_tfidf = vectorizer_tfidf.fit_transform(newsgroups_train.data) # (documents, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam=1e3 # adding a penalty to elements in matrix W and H that \n",
    "lr=1e-2\n",
    "m, n = vectors_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# again showing the scikit learn implementation\n",
    "W1 = clf.fit_transform(vectors)\n",
    "H1 = clf.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jpeg  image  gif  file  color  images  format  quality  version  files',\n",
       " 'edu  graphics  pub  mail  128  ray  ftp  send  3d  com',\n",
       " 'space  launch  satellite  nasa  commercial  satellites  year  market  data  earth',\n",
       " 'jesus  god  people  matthew  atheists  does  atheism  said  just  believe',\n",
       " 'image  data  available  software  processing  ftp  edu  analysis  images  display']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_topics(H1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that will be used in the algorithm\n",
    "mu = 1e-6\n",
    "def grads(M, W, H):\n",
    "    R = W@H-M\n",
    "    return R@H.T + penalty(W, mu)*lam, W.T@R + penalty(H, mu)*lam # dW, dH\n",
    "# gradients             dW          ,      dH\n",
    "# (R@H.T) + penalty(W, mu)*lam, (W.T@R) + penalty(H, mu)*lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penalty(M, mu):\n",
    "    return np.where(M>=mu,0, np.min(M - mu, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upd(M, W, H, lr):\n",
    "    dW,dH = grads(M,W,H)\n",
    "    W -= lr*dW; H -= lr*dH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(M,W,H): \n",
    "    print(np.linalg.norm(M-W@H), W.min(), H.min(), (W<0).sum(), (H<0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first step randomly selected matricies on the start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.abs(np.random.normal(scale=0.01, size=(m,d)))\n",
    "H = np.abs(np.random.normal(scale=0.01, size=(d,n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.426322753337054 3.747596378108558e-07 5.255131490501768e-08 0 0\n"
     ]
    }
   ],
   "source": [
    "report(vectors_tfidf, W, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "upd(vectors_tfidf,W,H,lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.412841616838115 -0.0008762465457564088 -6.499032853738646e-05 120 275\n"
     ]
    }
   ],
   "source": [
    "report(vectors_tfidf, W, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.40773296917012 -0.0007039856270306101 -6.728324518435599e-05 110 259\n",
      "44.37198108881029 -0.00034831271386828093 -5.343467486668645e-05 37 571\n",
      "44.343228400604715 -0.00019804602946757476 -7.59628792011033e-05 34 1002\n",
      "44.31098382233254 -0.000141909799651099 -9.63252312504018e-05 33 1582\n",
      "44.27583885193021 -8.373355912219938e-05 -0.00010304481998523988 31 2260\n"
     ]
    }
   ],
   "source": [
    "for i in range(50): \n",
    "    upd(vectors_tfidf,W,H,lr)\n",
    "    if i % 10 == 0: report(vectors_tfidf,W,H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['space  people  don  just  god  like  think  know  does  nasa',\n",
       " 'god  don  space  think  people  just  know  like  does  time',\n",
       " 'don  people  god  like  space  just  know  think  does  say',\n",
       " 'space  don  just  people  god  like  think  know  does  good',\n",
       " 'god  don  space  people  think  know  just  like  does  jesus']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_topics(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trucated SVD implementation from scratch\n",
    "# truncated means that we are going to compute SVD on matrix with fewer columns than A has, but with approx. same column space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a process to calculate a truncated SVD, described in [Finding Structure with Randomness: Probabilistic Algorithms for Constructing Approximate Matrix Decompositions](https://arxiv.org/pdf/0909.4061.pdf) and [summarized in this blog post](https://research.fb.com/fast-randomized-svd/):\n",
    "\n",
    "1\\. Compute an approximation to the range of $A$. That is, we want $Q$ with $r$ orthonormal columns such that $$A \\approx QQ^TA$$\n",
    "\n",
    "\n",
    "2\\. Construct $B = Q^T A$, which is small ($r\\times n$)\n",
    "\n",
    "\n",
    "3\\. Compute the SVD of $B$ by standard methods (fast since $B$ is smaller than $A$), $B = S\\,\\Sigma V^T$\n",
    "\n",
    "4\\. Since $$ A \\approx Q Q^T A = Q (S\\,\\Sigma V^T)$$ if we set $U = QS$, then we have a low rank approximation $A \\approx U \\Sigma V^T$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So how do we find $Q$ (in step 1)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To estimate the range of $A$, we can just take a bunch of random vectors $w_i$, evaluate the subspace formed by $Aw_i$.  We can form a matrix $W$ with the $w_i$ as it's columns.  Now, we take the QR decomposition of $AW = QR$, then the columns of $Q$ form an orthonormal basis for $AW$, which is the range of $A$.\n",
    "\n",
    "Since the matrix $AW$ of the product has far more rows than columns and therefore, approximately, orthonormal columns. This is simple probability - with lots of rows, and few columns, it's unlikely that the columns are linearly dependent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The QR Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be learning about the QR decomposition **in depth** later on.  For now, you just need to know that $A = QR$, where $Q$ consists of orthonormal columns, and $R$ is upper triangular.  Trefethen says that the QR decomposition is the most important idea in numerical linear algebra!  We will definitely be returning to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How should we choose $r$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose our matrix has 100 columns, and we want 5 columns in U and V. To be safe, we should project our matrix onto an orthogonal basis with a few more rows and columns than 5 (let's use 15).  At the end, we will just grab the first 5 columns of U and V\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing randomized SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computes an orthonormal matrix whose range approximates the range of A\n",
    "# we can use different methods how to finds such vectors that approximates column space of A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomized_range_finder(A, size, n_iter=5):\n",
    "    Q = np.random.normal(size=(A.shape[1], size))\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        Q, _ = linalg.lu(A @ Q, permute_l=True)\n",
    "        Q, _ = linalg.lu(A.T @ Q, permute_l=True)\n",
    "        \n",
    "    Q, _ = linalg.qr(A @ Q, mode='economic')\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomized_svd(M, n_components, n_oversamples=10, n_iter=4):\n",
    "    n_random = n_components + n_oversamples\n",
    "    \n",
    "    Q = randomized_range_finder(M, n_random, n_iter)\n",
    "    \n",
    "    #project M to the (k+p) dimensional space using the basis vectors\n",
    "    B = Q.T @ M\n",
    "    \n",
    "    #compute the SVD on the thin matrix: (k + p ) wide\n",
    "    Uhat, s, V = linalg.svd(B, full_matrices=False)\n",
    "    del B\n",
    "    U = Q @ Uhat\n",
    "    \n",
    "    return U[:, :n_components], s[:n_components], V[:n_components, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.35 s, sys: 1.52 s, total: 4.87 s\n",
      "Wall time: 3.32 s\n"
     ]
    }
   ],
   "source": [
    "%time u, s, v = randomized_svd(vectors, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([433.92698542, 291.51012732, 240.71137428, 220.00047344,\n",
       "       182.74466786])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jpeg  image  edu  file  graphics  images  gif  data  pub  ftp',\n",
       " 'edu  graphics  data  space  pub  mail  128  3d  ray  nasa',\n",
       " 'space  jesus  launch  god  people  satellite  matthew  atheists  does  time',\n",
       " 'jesus  god  matthew  people  atheists  atheism  does  graphics  religious  said',\n",
       " 'jpeg  graphics  space  pub  edu  ray  mail  send  launch  file']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_topics(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
